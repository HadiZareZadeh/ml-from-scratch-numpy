{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparison: From-Scratch vs Scikit-Learn\n",
        "\n",
        "This notebook compares our from-scratch implementations with scikit-learn's optimized versions to validate correctness and understand performance differences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression as SklearnLinearRegression\n",
        "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression, Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
        "from linear_regression import LinearRegression\n",
        "from logistic_regression import LogisticRegression\n",
        "\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "with open('../data_preprocessed.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "X_train = data['X_train']\n",
        "X_test = data['X_test']\n",
        "y_train = data['y_train']\n",
        "y_test = data['y_test']\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Our implementation\n",
        "print(\"Training from-scratch model...\")\n",
        "start_time = time.time()\n",
        "our_model = LinearRegression(learning_rate=0.01, max_iterations=2000, verbose=False)\n",
        "our_model.fit(X_train_scaled, y_train)\n",
        "our_time = time.time() - start_time\n",
        "our_pred = our_model.predict(X_test_scaled)\n",
        "our_mse = mean_squared_error(y_test, our_pred)\n",
        "our_r2 = r2_score(y_test, our_pred)\n",
        "\n",
        "# Scikit-learn\n",
        "print(\"Training sklearn model...\")\n",
        "start_time = time.time()\n",
        "sklearn_model = SklearnLinearRegression()\n",
        "sklearn_model.fit(X_train_scaled, y_train)\n",
        "sklearn_time = time.time() - start_time\n",
        "sklearn_pred = sklearn_model.predict(X_test_scaled)\n",
        "sklearn_mse = mean_squared_error(y_test, sklearn_pred)\n",
        "sklearn_r2 = r2_score(y_test, sklearn_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LINEAR REGRESSION COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nFrom-Scratch Implementation:\")\n",
        "print(f\"  Training Time: {our_time:.4f} seconds\")\n",
        "print(f\"  Test MSE: {our_mse:.6f}\")\n",
        "print(f\"  Test R²: {our_r2:.6f}\")\n",
        "print(f\"\\nScikit-Learn Implementation:\")\n",
        "print(f\"  Training Time: {sklearn_time:.4f} seconds\")\n",
        "print(f\"  Test MSE: {sklearn_mse:.6f}\")\n",
        "print(f\"  Test R²: {sklearn_r2:.6f}\")\n",
        "print(f\"\\nDifference:\")\n",
        "print(f\"  MSE Difference: {abs(our_mse - sklearn_mse):.6f}\")\n",
        "print(f\"  R² Difference: {abs(our_r2 - sklearn_r2):.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare predictions\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, our_pred, alpha=0.5, s=20, label='From-Scratch')\n",
        "plt.scatter(y_test, sklearn_pred, alpha=0.5, s=20, label='Sklearn', marker='x')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predictions Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(our_pred, sklearn_pred, alpha=0.5, s=20)\n",
        "plt.plot([our_pred.min(), our_pred.max()], [our_pred.min(), our_pred.max()], 'r--', linewidth=2)\n",
        "plt.xlabel('From-Scratch Predictions')\n",
        "plt.ylabel('Sklearn Predictions')\n",
        "plt.title('Prediction Agreement')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation between predictions\n",
        "pred_corr = np.corrcoef(our_pred, sklearn_pred)[0, 1]\n",
        "print(f\"\\nCorrelation between predictions: {pred_corr:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression Comparison\n",
        "\n",
        "For logistic regression, we'll convert the regression problem to classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to binary classification\n",
        "threshold = np.median(y_train)\n",
        "y_train_binary = (y_train > threshold).astype(int)\n",
        "y_test_binary = (y_test > threshold).astype(int)\n",
        "\n",
        "# Our implementation\n",
        "print(\"Training from-scratch logistic regression...\")\n",
        "start_time = time.time()\n",
        "our_log_model = LogisticRegression(learning_rate=0.1, max_iterations=2000, verbose=False)\n",
        "our_log_model.fit(X_train_scaled, y_train_binary)\n",
        "our_log_time = time.time() - start_time\n",
        "our_log_pred = our_log_model.predict(X_test_scaled)\n",
        "our_log_acc = accuracy_score(y_test_binary, our_log_pred)\n",
        "\n",
        "# Scikit-learn\n",
        "print(\"Training sklearn logistic regression...\")\n",
        "start_time = time.time()\n",
        "sklearn_log_model = SklearnLogisticRegression(max_iter=2000, random_state=42)\n",
        "sklearn_log_model.fit(X_train_scaled, y_train_binary)\n",
        "sklearn_log_time = time.time() - start_time\n",
        "sklearn_log_pred = sklearn_log_model.predict(X_test_scaled)\n",
        "sklearn_log_acc = accuracy_score(y_test_binary, sklearn_log_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LOGISTIC REGRESSION COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nFrom-Scratch Implementation:\")\n",
        "print(f\"  Training Time: {our_log_time:.4f} seconds\")\n",
        "print(f\"  Test Accuracy: {our_log_acc:.6f}\")\n",
        "print(f\"\\nScikit-Learn Implementation:\")\n",
        "print(f\"  Training Time: {sklearn_log_time:.4f} seconds\")\n",
        "print(f\"  Test Accuracy: {sklearn_log_acc:.6f}\")\n",
        "print(f\"\\nDifference:\")\n",
        "print(f\"  Accuracy Difference: {abs(our_log_acc - sklearn_log_acc):.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Correctness**: Our implementations produce similar results to sklearn, validating correctness\n",
        "2. **Performance**: Sklearn is faster due to optimized C implementations and better numerical methods\n",
        "3. **Educational Value**: From-scratch implementation provides deep understanding of algorithms\n",
        "4. **Trade-offs**: Production systems use optimized libraries, but understanding fundamentals is crucial\n",
        "\n",
        "Our implementations serve as educational tools to understand the mathematical foundations and implementation details of these fundamental algorithms.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
